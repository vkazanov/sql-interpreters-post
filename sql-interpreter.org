* Аннотация

  Сбор, хранение, преобразование и презентация данных - суть работы инженеров данных (англ. data
  engineer). Отдел Business Intelligence группы компаний Badoo в сутки принимает и обрабатывает
  больше 20 миллиардов событий, отправляемых с пользовательских устройств, или 2 терабайта входящих
  данных в сутки.

  Исследование и интерпретация всех этих данных - не всегда тривиальная задача, и может возникнуть
  желание выйти за рамки возможностей готовых баз данных. Но даже если вы набрались смелости и
  решили делать что-то новое, то следует сначала хотя бы ознакомиться с принципами работы уже
  существующих решений.

  Словом, любопытствующим и сильным духом разработчикам представляю описание традиционной модели
  исполнения запросов в реляционных БД на примере языка PigletQL.

* Содержание                                                           :TOC:
- [[#аннотация][Аннотация]]
- [[#предыстория][Предыстория]]
- [[#структура-интерпретатора-sql][Структура интерпретатора SQL]]
- [[#модель-volcano-и-исполнение-запросов][Модель Volcano и исполнение запросов]]
- [[#pigletql][PigletQL]]
  - [[#лексический-и-синтаксический-анализаторы][Лексический и синтаксический анализаторы]]
  - [[#семантический-анализатор][Семантический анализатор]]
  - [[#компиляция-запросов-в-промежуточное-представление][Компиляция запросов в промежуточное представление]]
  - [[#исполнение-промежуточного-представления][Исполнение промежуточного представления]]
  - [[#операторы][Операторы]]
  - [[#примеры-работы][Примеры работы]]
- [[#выводы][Выводы]]
- [[#литература][Литература]]

* Предыстория

  Моя группа инженеров занимается бэкэндами и интерфейсами, предоставляющими возможности для анализа
  и исследования данных внутри компании. Наши стандартные инструменты это традиционные реляционные
  базы данных, работающие на единицах серверов (MySQL), распределенные реляционные базы данных
  (Exasol) в десятки серверов и распределенные базы данных, работающие в кластере Hadoop размером в
  сотню машин (Hive и Presto).

  Большая часть наших запросов к БД - аналитические, то есть затрагивают от сотен тысяч до
  миллиардов записей. Такие запросы занимают десятки минут или даже часы в зависимости от
  используемого решения и сложности запроса. При ручной работе пользователя-аналитика такое время
  исполнения запроса считается приемлемым, но для интерактивного исследования через пользовательский
  интерфейс не подходит.

  Со временем мы выделили популярные аналитические запросы и запросы, с трудом излагаемые в терминах
  SQL, и разработали небольшие специализированные базы данных под них. Эти БД хранят подмножество
  данных в подходящем для легковесных алгоритмов сжатия формате (напр., streamvbyte). Такой формат
  позволяет хранить в памяти на единственной машине данные за несколько дней и исполнять запросы за
  секунды.

  Поначалу языки запросов к этим данным и их интерпретаторы были наивными, и нам, разработчиками,
  приходилось постоянно их дорабатывать, и каждая доработка занимала непропорционально много
  времени.

  Языки запросов выходили недостаточно гибкими, хотя очевидных причин для ограничения возможностей
  языков не было. Со временем мы обратились к опыту разработчиков интерпретаторов SQL, благодаря
  чему, надеюсь, предупредим будущие проблемы.

  Я расскажу про самую распространенную модель исполнения запросов в реляционных БД - модель
  Volcano. К статье прилагается исходный код интерпретатора примитивного диалекта SQL - [[https://github.com/vkazanov/sql-interpreters-post][PigletQL]],
  поэтому интересующиеся легко могут ознакомиться с деталями в репозитории.

* Структура интерпретатора SQL

  [[file:img/General%20SQL%20Intepreter%20Structure.svg]]

  Большая часть популярных баз данных предоставляет интерфейс к данным в виде декларативного языка
  запросов SQL. Запрос в виде строки преобразуется синтаксическим анализатором в описание запроса,
  похожее на дерево абстрактного синтаксиса. Несложные запросы возможно выполнять уже на этом этапе,
  однако для оптимизирующих преобразований и последующего исполнения это представление неудобно. В
  известных мне БД для этих целей вводятся промежуточные представления.

  Основным образцом для промежуточных представлений стала реляционная алгебра. Реляционная алгебра -
  язык, где явно описываются преобразования (/операторы/), проводимые над данными: выбор подмножества
  данных по предикату, соединение данных из разных источников и так далее. Кроме того, реляционная
  алгебра - алгебра в математическом смысле, то есть для нее формализовано большое число
  эквивалентных преобразований. Над запросом в форме дерева операторов реляционной алгебры удобно
  проводить оптимизирующие преобразования.

  Существуют важные отличия между внутренними представлениями в базах данных и оригинальной
  реляционной алгеброй, поэтому правильней ее называть /логической алгеброй/.

  Проверка валидности запроса обычно проводится при компиляции первоначального представления запроса
  в операторы логической алгебры и соответствует стадии семантического анализа в обычных
  компиляторах. Роль таблицы символов в базах данных играет /каталог базы данных/, где хранится
  информация о /схеме/ и метаданных базы данных: таблицах, колонках таблиц, правах пользователей и
  т.д.

  По сравнению с интерпретаторами языков общего назначения у интерпретаторов баз данных есть еще
  одна особенность: различия в объеме данных и метаинформации о данных, к которым предполагается
  делать запросы. В таблицах (/отношениях/ в терминах реляционной алгебры и документации некоторых БД)
  может быть разное количество даннымх, на некоторых колонках (/атрибутах/ отношений) могут быть
  построены индексы и т.д. То есть в зависимости от /схемы/ и данных в БД запрос надо исполнять
  разными алгоритмами и разном порядке.

  Для решения этой задачи вводится еще одно промежуточное представление - /физическая алгебра/. В
  зависимости от наличия индексов на колонках, объема данных в таблицах и структуры дерева
  логической алгебры предлагаются разные формы дерева физической алгебры, из которых выбирается
  оптимальный вариант. Именно это дерево показывают БД в качестве плана запроса. В обычных
  компиляторах этому этапу условно соответствуют этапы распределения регистров, планирования и
  выбора инструкций.

  Последним этапом работы интерпретатора является непосредственно исполнение дерева операторов
  физической алгебры.

* Модель Volcano и исполнение запросов

  Интерпретаторы дерева физической алгебры в закрытых коммерческих БД использовались практически
  всегда, но академическая литература на эту тему обычно ссылается на экспериментальный оптимизатор
  Volcano, разрабатывавшийся в начале 90-х.

  В модели Volcano операторы дерева физической алгебры каждый превращается в структуру с тремя
  функциями: open, next, close. Кроме функций оператор содержит рабочее состояние - state. Функция
  open инициирует состояние оператора, функция next возвращает либо следующий /кортеж/ (англ. tuple),
  либо NULL если кортежей не осталось. Функция close заканчивает работу оператора:

  [[file:img/Volcano%20Operator.svg]]

  Операторы могут быть вложены друг в друга, формируя дерево операторов физической алгебры. Каждый
  оператор перебирает кортежи либо существующего на реальном носителе отношения, либо виртуального
  отношения, определяемого кортежами из вложенных операторов:

  [[file:img/Volcano%20Model.svg]]

  В терминах современных языков высокого уровня дерево таких операторов представляет собой каскад
  итераторов.

  От модели Volcano отталкиваются даже промышленные интерпретаторы запросов в реляционных СУБД,
  поэтому именно эту модель я взял в качестве основы интерпретатора PigletQL.

* PigletQL

  [[file:img/PigletQL%20Structure.svg]]

  PigletQL написан на языке Си, поддерживает создание таблиц в стиле SQL, но ограничивается
  единственным типом - 32-битными положительными целыми числами. Все таблицы располагаются в памяти.
  Система работает в один поток, не предлагает механизма транзакций. В PigletQL нет оптимизатора, и
  запросы SELECT компилируются прямо в дерево операторов физической алгебры, остальные же запросы
  (CREATE TABLE и INSERT) исполняются сразу после разбора строки запроса.

  Пример сессии пользователя в PigletQL:

  #+BEGIN_EXAMPLE
  > ./pigletql
  > CREATE TABLE tab1 (col1,col2,col3);
  > INSERT INTO tab1 VALUES (1,2,3);
  > INSERT INTO tab1 VALUES (4,5,6);
  > SELECT col1,col2,col3 FROM tab1;
  col1 col2 col3
  1 2 3
  4 5 6
  rows: 2
  > SELECT col1 FROM tab1 ORDER BY col1 DESC;
  col1
  4
  1
  rows: 2
  #+END_EXAMPLE

** Лексический и синтаксический анализаторы

   PigletQL - очень простой язык и никаких сторонних инструментов на этапах лексического и
   синтаксического анализа его реализация не потребовала.

   Вручную написанный лексический анализатор получает строку запроса на вход и отдает один за другим
   лексемы (токены). Из строки запроса создается объект лексического анализатора (scanner_t),
   который и отдает токены один за другим:

   #+BEGIN_SRC c

   scanner_t *scanner_create(const char *string);

   void scanner_destroy(scanner_t *scanner);

   token_t scanner_next(scanner_t *scanner);

   #+END_SRC

   Синтаксический анализ проводится методом рекурсивного спуска. Сначала создается объект parser_t,
   который, получив лексический анализатор (scanner_t), заполняет объект query_t информацией о
   запросе:

   #+BEGIN_SRC c

   query_t *query_create(void);

   void query_destroy(query_t *query);

   parser_t *parser_create(void);

   void parser_destroy(parser_t *parser);

   bool parser_parse(parser_t *parser, scanner_t *scanner, query_t *query);

   #+END_SRC

   Результат разбора в query_t - один из трех поддерживаемых PigletQL видов запроса:

   #+BEGIN_SRC c

     typedef enum query_tag {
         QUERY_SELECT,
         QUERY_CREATE_TABLE,
         QUERY_INSERT,
     } query_tag;

     /*
      * ... query_select_t, query_create_table_t, query_insert_t definitions ...
      **/

     typedef struct query_t {
         query_tag tag;
         union {
             query_select_t select;
             query_create_table_t create_table;
             query_insert_t insert;
         } as;
     } query_t;

   #+END_SRC

   Самый сложный вид запросов в PigletQL - SELECT. Ему соответствует структура данных
   query_select_t:

   #+BEGIN_SRC c

   typedef struct query_select_t {
       /* Attributes to output */
       attr_name_t attr_names[MAX_ATTR_NUM];
       uint16_t attr_num;

       /* Relations to get tuples from */
       rel_name_t rel_names[MAX_REL_NUM];
       uint16_t rel_num;

       /* Predicates to apply to tuples */
       query_predicate_t predicates[MAX_PRED_NUM];
       uint16_t pred_num;

       /* Pick an attribute to sort by */
       bool has_order;
       attr_name_t order_by_attr;
       sort_order_t order_type;
   } query_select_t;

   #+END_SRC

   Структура содержит описание запроса: массив запрошенных пользователем атрибутов; список
   источников данных - отношений; массив предикатов, фильтрующих кортежи; и информация об атрибуте,
   используемом для сортировки результатов.

** Семантический анализатор

   Фаза семантического анализа в обычном SQL включает проверку существования перечисленных таблиц,
   колонок в таблицах и проверки типов в выражениях запроса. Для проверок, связанных с таблицами и
   колонками, используется /каталог/ базы данных, где хранится вся информация о структуре данных БД.

   В PigletQL сложных выражений не бывает, поэтому проверка запроса сводится к проверке метаданных
   таблиц и колонок по каталогу. Запросы SELECT, например, проверяются функцией validate_select.
   Приведу функцию в сокращенном виде:

   #+BEGIN_SRC c

     static bool validate_select(catalogue_t *cat, const query_select_t *query)
     {
         /* All the relations should exist */
         for (size_t rel_i = 0; rel_i < query->rel_num; rel_i++) {
             if (catalogue_get_relation(cat, query->rel_names[rel_i]))
                 continue;

             fprintf(stderr, "Error: relation '%s' does not exist\n", query->rel_names[rel_i]);
             return false;
         }

         /* Relation names should be unique */
         if (!rel_names_unique(query->rel_names, query->rel_num))
             return false;

         /* Attribute names should be unique */
         if (!attr_names_unique(query->attr_names, query->attr_num))
             return false;

         /* Attributes should be present in relations listed */
         /* ... */

         /* ORDER BY attribute should be available in the list of attributes chosen */
         /* ... */

         /* Predicate attributes should be available in the list of attributes projected */
         /* ... */

         return true;
     }

   #+END_SRC

   Если запрос валиден, то следующим этапом становится компиляция дерева разбора в дерево
   операторов.

** Компиляция запросов в промежуточное представление

   [[file:img/Compiling%20PigletQL%20Query%20Tree.svg]]

   В полноценных интерпретаторах SQL промежуточных представлений, как правило, два: логическая и
   физическая алгебра.

   Простой интерпретатор PigletQL запросы CREATE TABLE или INSERT исполняет непосредственно из своих
   деревьев разбора, то есть структур query_create_table_t и query_insert_t. Более сложные запросы
   SELECT компилируются в единственное промежуточное представление, которое и будет исполняться
   интерпретатором.

   Дерево операторов строится относительно снизу вверх, в следующей последовательности:

   1. Из правой части запроса ("... FROM relation1, relation2, ...") получаются имена искомых
      отношений, для каждого из которых создается оператор scan.

   2. Извлекающие кортежи из отношений операторы scan объединяются в левостороннее двоичное дерево
      через оператор join.

   3. Атрибуты, запрошенные пользователем ("SELECT attr1, attr2 ..."), выбираются оператором
      project.

   4. Если указаны какие-либо предикаты ("... WHERE a=1 AND b>10 ..."), то к дереву сверху
      добавляется оператор select.

   5. Если указан способ сортировки результата ("... ORDER BY attr1 DESC"), то к вершине дерева
      добавляется оператор sort.

   Компиляция в коде PigletQL:

   #+BEGIN_SRC c

     operator_t *compile_select(catalogue_t *cat, const query_select_t *query)
     {
         /* Current root operator */
         operator_t *root_op = NULL;

         /* 1. Scan ops */
         /* 2. Join ops*/

         {
             size_t rel_i = 0;
             relation_t *rel = catalogue_get_relation(cat, query->rel_names[rel_i]);
             root_op = scan_op_create(rel);
             rel_i += 1;

             for (; rel_i < query->rel_num; rel_i++) {
                 rel = catalogue_get_relation(cat, query->rel_names[rel_i]);
                 operator_t *scan_op = scan_op_create(rel);
                 root_op = join_op_create(root_op, scan_op);
             }
         }

         /* 3. Project */
         root_op = proj_op_create(root_op, query->attr_names, query->attr_num);

         /* 4. Select */
         if (query->pred_num > 0) {
             operator_t *select_op = select_op_create(root_op);
             for (size_t pred_i = 0; pred_i < query->pred_num; pred_i++) {
                 query_predicate_t predicate = query->predicates[pred_i];

                 /* Add a predicate to the select operator */
                 /* ... */
             }
             root_op = select_op;
         }

         /* 5. Sort */
         if (query->has_order)
             root_op = sort_op_create(root_op, query->order_by_attr, query->order_type);

         return root_op;
     }

   #+END_SRC

   После формирования дерева обычно проводятся оптимизирующие преобразования, но PigletQL сразу
   переходит к этапу исполнения.

** Исполнение промежуточного представления

   [[file:img/PigletQL%20Tuple%20Path.svg]]

   Модель исполнения Volcano подразумевает интерфейс работы с операторами через три общие для всех
   операторов операции open/next/close. В сущности, каждый оператор Volcano - итератор, из которого
   кортежи "вытягиваются" один за другим, поэтому такой подход к исполнению еще называется
   pull-моделью.

   Каждый из таких итераторов может сам вызвать те же функции вложенных итераторов, сформировать
   временные таблицы или преобразовать входящие кортежи.

   Исполнение запросов SELECT в PigletQL:

   #+BEGIN_SRC c

   bool eval_select(catalogue_t *cat, const query_select_t *query)
   {
       /* Compile the operator tree:  */
       operator_t *root_op = compile_select(cat, query);


       /* Eval the tree: */
       {
           root_op->open(root_op->state);

           size_t tuples_received = 0;
           tuple_t *tuple = NULL;
           while((tuple = root_op->next(root_op->state))) {
               /* attribute list for the first row only */
               if (tuples_received == 0)
                   dump_tuple_header(tuple);

               /* A table of tuples */
               dump_tuple(tuple);

               tuples_received++;
           }
           printf("rows: %zu\n", tuples_received);

           root_op->close(root_op->state);
       }

       root_op->destroy(root_op);

       return true;
   }

   #+END_SRC

   Здесь запрос сначала компилируется функцией compile_select, возвращающей корень дерева
   операторов; после чего у корневого оператора вызываются те самые open/next/close. Каждый вызов
   next либо возвращает следующий кортеж, либо NULL. В последнем случае все кортежи были извлечены,
   и следует вызвать закрывающую итератор функцию close.

   Полученные кортежи пересчитываются и выводятся таблицей в стандартный поток вывода.

** Операторы

   Самое интересное в PigletQL - дерево операторов, и хочется показать устройство некоторых из них.

   Интерфейс у всех операторов общий и состоит из указателей на функции open/next/close и
   дополнительной служебная функция (destroy), высвобождающей ресурсы всего дерева операторов разом:

   #+BEGIN_SRC c

   typedef void (*op_open)(void *state);
   typedef tuple_t *(*op_next)(void *state);
   typedef void (*op_close)(void *state);
   typedef void (*op_destroy)(operator_t *op);

   /* The operator itself is just 4 pointers to related ops and operator state */
   struct operator_t {
       op_open open;
       op_next next;
       op_close close;
       op_destroy destroy;

       void *state;
   } ;

   #+END_SRC

   Помимо функций в операторе может содержаться произвольное внутреннее состояние (указатель state).

   Ниже я разберу устройство двух интересных операторов: простейший scan и создающий промежуточное
   отношение sort.

*** Оператор scan

   Оператор, с которого начинается выполнение любого запроса - scan. Он просто перебирает все
   кортежи отношения. Внутреннее состояние у scan это указатель на отношение, откуда будут
   извлекаться кортежи, индекс следующего кортежа в отношении и структура-ссылка на текущий кортеж,
   переданный пользователю:

   #+BEGIN_SRC c

   typedef struct scan_op_state_t {
       /* A reference to the relation being scanned */
       const relation_t *relation;
       /* Next tuple index to retrieve from the relation */
       uint32_t next_tuple_i;
       /* A structure to be filled with references to tuple data */
       tuple_t current_tuple;
   } scan_op_state_t;

   #+END_SRC

   Для создания состояния оператора scan необходимо отношение-источник, все остальное (указатели на
   соответствующие функции) уже известно:

   #+BEGIN_SRC c

   operator_t *scan_op_create(const relation_t *relation)
   {
       operator_t *op = calloc(1, sizeof(*op));
       assert(op);

       *op = (operator_t) {
           .open = scan_op_open,
           .next = scan_op_next,
           .close = scan_op_close,
           .destroy = scan_op_destroy,
       };

       scan_op_state_t *state = calloc(1, sizeof(*state));
       assert(state);

       *state = (scan_op_state_t) {
           .relation = relation,
           .next_tuple_i = 0,
           .current_tuple.tag = TUPLE_SOURCE,
           .current_tuple.as.source.tuple_i = 0,
           .current_tuple.as.source.relation = relation,
       };
       op->state = state;


       return op;
   }

   #+END_SRC

   Операции open/close в случае scan сбрасывают ссылки обратно на первый элемент отношения:

   #+BEGIN_SRC c

   void scan_op_open(void *state)
   {
       scan_op_state_t *op_state = (typeof(op_state)) state;
       op_state->next_tuple_i = 0;
       tuple_t *current_tuple = &op_state->current_tuple;
       current_tuple->as.source.tuple_i = 0;
   }

   void scan_op_close(void *state)
   {
       scan_op_state_t *op_state = (typeof(op_state)) state;
       op_state->next_tuple_i = 0;
       tuple_t *current_tuple = &op_state->current_tuple;
       current_tuple->as.source.tuple_i = 0;
   }

   #+END_SRC

   Вызов next либо возвращает следующий кортеж, либо NULL, если кортежей в отношении больше нет:

   #+BEGIN_SRC c

   tuple_t *scan_op_next(void *state)
   {
       scan_op_state_t *op_state = (typeof(op_state)) state;
       if (op_state->next_tuple_i >= op_state->relation->tuple_num)
           return NULL;

       tuple_source_t *source_tuple = &op_state->current_tuple.as.source;
       source_tuple->tuple_i = op_state->next_tuple_i;
       op_state->next_tuple_i++;

       return &op_state->current_tuple;
   }

   #+END_SRC

*** Оператор sort

    Оператор sort выдает кортежи в заданном пользователем порядке. Для этого надо создать временную
    таблицу с кортежами, полученными из вложенных операторов, и отсортировать.

    Внутреннее состояние оператора:

    #+BEGIN_SRC c

    typedef struct sort_op_state_t {
        operator_t *source;
        /* Attribute to sort tuples by */
        attr_name_t sort_attr_name;
        /* Sort order, descending or ascending */
        sort_order_t sort_order;

        /* Temporary relation to be used for sorting*/
        relation_t *tmp_relation;
        /* Relation scan op */
        operator_t *tmp_relation_scan_op;
    } sort_op_state_t;

    #+END_SRC

    Сортировка проводится по указанным в запросе атрибутам (sort_attr_name и sort_order) над
    временное отношеним (tmp_relation). Все это происходит во время вызова функции open:

    #+BEGIN_SRC c

    void sort_op_open(void *state)
    {
        sort_op_state_t *op_state = (typeof(op_state)) state;
        operator_t *source = op_state->source;

        /* Materialize a table to be sorted */
        source->open(source->state);
        tuple_t *tuple = NULL;
        while((tuple = source->next(source->state))) {
            if (!op_state->tmp_relation) {
                op_state->tmp_relation = relation_create_for_tuple(tuple);
                assert(op_state->tmp_relation);
                op_state->tmp_relation_scan_op = scan_op_create(op_state->tmp_relation);
            }
            relation_append_tuple(op_state->tmp_relation, tuple);
        }
        source->close(source->state);

        /* Sort it */
        relation_order_by(op_state->tmp_relation, op_state->sort_attr_name, op_state->sort_order);

        /* Open a scan op on it */
        op_state->tmp_relation_scan_op->open(op_state->tmp_relation_scan_op->state);
    }

    #+END_SRC

    Перебор элементов временного отношения проводится временным оператором tmp_relation_scan_op:

    #+BEGIN_SRC c

    tuple_t *sort_op_next(void *state)
    {
        sort_op_state_t *op_state = (typeof(op_state)) state;
        return op_state->tmp_relation_scan_op->next(op_state->tmp_relation_scan_op->state);;
    }

    #+END_SRC

    Временное отношение деаллоцируется в функции close:

    #+BEGIN_SRC c

    void sort_op_close(void *state)
    {
        sort_op_state_t *op_state = (typeof(op_state)) state;
        /* If there was a tmp relation - destroy it */
        if (op_state->tmp_relation) {
            op_state->tmp_relation_scan_op->close(op_state->tmp_relation_scan_op->state);
            scan_op_destroy(op_state->tmp_relation_scan_op);
            relation_destroy(op_state->tmp_relation);
            op_state->tmp_relation = NULL;
        }
    }

    #+END_SRC

    Отсюда хорошо видно, почему операции сортировки на колонках без индексов могут занимать довольно
    много времени.

** Примеры работы

   Приведу несколько примеров запросов PigletQL с соответствующими деревьями физической алгебры.

   Самый простой пример, где выбираются все кортежи из таблицы:

   #+BEGIN_EXAMPLE

   > ./pigletql
   > create table rel1 (a1,a2,a3);
   > insert into rel1 values (1,2,3);
   > insert into rel1 values (4,5,6);
   > select a1 from rel1;
   a1
   1
   4
   rows: 2
   >

   #+END_EXAMPLE

   Для простейшего из запросов используются только извлекающий кортежи из отношения scan и
   выделяющий у кортежей единственный атрибут project:

   [[file:img/Project%20Example.svg]]

   Выбор кортежей с предикатом:

   #+BEGIN_EXAMPLE

   > ./pigletql
   > create table rel1 (a1,a2,a3);
   > insert into rel1 values (1,2,3);
   > insert into rel1 values (4,5,6);
   > select a1 from rel1 where a1 > 3;
   a1
   4
   rows: 1
   >

   #+END_EXAMPLE

   Предикаты выражаются оператором select:

   [[file:img/Select%20Example.svg]]

   Выбор кортежей с сортировкой:

   #+BEGIN_EXAMPLE

   > ./pigletql
   > create table rel1 (a1,a2,a3);
   > insert into rel1 values (1,2,3);
   > insert into rel1 values (4,5,6);
   > select a1 from rel1 order by a1 desc;
   a1
   4
   1
   rows: 2

   #+END_EXAMPLE

   Оператор сортировки scan в вызове open создает (/материализует/) временное отношение, помещает туда
   все входящие кортежи и сортирует целиком. После чего выводит в вызовах next кортежи из временного
   отношения в указанном пользователем порядке:

   [[file:img/Sort%20Example.svg]]

   Соединение кортежей двух таблиц с предикатом:

   #+BEGIN_EXAMPLE

   > ./pigletql
   > create table rel1 (a1,a2,a3);
   > insert into rel1 values (1,2,3);
   > insert into rel1 values (4,5,6);
   > create table rel2 (a4,a5,a6);
   > insert into rel2 values (7,8,6);
   > insert into rel2 values (9,10,6);
   > select a1,a2,a3,a4,a5,a6 from rel1, rel2 where a3=a6;
   a1 a2 a3 a4 a5 a6
   4 5 6 7 8 6
   4 5 6 9 10 6
   rows: 2

   #+END_EXAMPLE

   Оператор join в PigletQL не использует никаких сложных алгоритмов, а просто формирует декартово
   произведение из множеств кортежей левого и правого поддеревьев. Это очень неэффективно, но для
   демонстрационного интерпретатора вполне сойдет:

   [[file:img/Join%20Select%20Example.svg]]

* Выводы

  Напоследок хочу заметить, что если вы делаете интерпретатор языка, похожего на SQL, то вам все же
  лучше взять любую из многочисленных доступных свободно (или несвободно) реляционных БД. В
  современные оптимизаторы и интерпретаторы запросов популярных баз данных вложены тысячи
  человеко-лет, и разработка даже простейших БД общего назначения занимает в лучшему случае годы.

  Демонстрационный язык PigletQL имитирует работу интерпретатора именно SQL, но реально в работе мы
  используем только отдельные элементы архитектуры Volcano, и для тех - редких! - видов запросов, которые
  трудно выразить в рамках реляционной модели.

  Тем не менее, повторюсь: даже поверхностное знакомство с архитектурой такого рода интерпретаторов
  пригодится в тех случаях, где требуется гибко работать с потоками данных.

* Литература

  - Sciore, E. (2008). Database design and implementation.

  - Garcia-Molina, H., Ullman, J. D., & Widom, J. (2000). Database system implementation.

  - Graefe, G. (1994). Volcano - an extensible and parallel query evaluation system.

  - Graefe, G. (1993). Query evaluation techniques for large databases.
