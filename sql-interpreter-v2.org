* Введение

  Сбор, хранение, преобразование и презентация данных - суть работы инженеров данных (англ. data
  engineer). До определенных объемов данных и в рамках стандартных задач почти всегда хватает
  возможностей уже существующих баз данных.

  Отдел Business Intelligence группы компаний Badoo в сутки принимает больше 20 миллиардов событий,
  отправляемых с пользовательских устройств, и на порядок больше технических уведомлений.

  Моя группа инженеров занимается бэкэндами и интерфейсами, предоставляющими возможности для анализа
  и исследования данных внутри компании. Но традиционные реляционные базы данных с такими объемами
  данных работать не могут; распределенные же БД работают относительно медленно, и не подходят для
  разработки интерактивных пользовательских интерфейсов.

  Для решения этих проблем группа разработала несколько специализированных баз данных, эффективно
  выполнявших узкое множество интересных запросов. Поначалу сами языки запросов и их интерпретаторы
  были наивными, и нам, разработчиками, приходилось постоянно их дорабатывать, и каждая доработка
  занимала непропорционально много времени.

  Языки запросов выходили недостаточно гибкими, хотя очевидных причин для ограничения возможностей
  языков запросов не было. Как стало ясно позже причиной проблем стало отсутствие опыта разработки
  интерпретаторов в целом, и интерпретаторов языков запросов к БД в частности. Со временем мы
  познакомились с устройством существующих интерпретаторов запросов и смогли решить большую часть
  имеющихся проблем.

  В статье я покажу, как можно разработать интерпретатор для примитивного диалекта SQL - PigletQL -
  и постараюсь провести параллели с компиляторами/интерпретаторами для языков программирования
  общего назначения.
* Содержание                                                           :TOC:
- [[#введение][Введение]]
- [[#структура-интерпретатора-sql][Структура интерпретатора SQL]]
- [[#модель-volcano-и-исполнение-запросов][Модель Volcano и исполнение запросов]]
- [[#pigletql][PigletQL]]
  - [[#лексический-и-синтаксический-анализаторы][Лексический и синтаксический анализаторы]]
  - [[#семантический-анализатор][Семантический анализатор]]
  - [[#компиляция-запросов-в-промежуточное-представление][Компиляция запросов в промежуточное представление]]
  - [[#исполнение-промежуточного-представления][Исполнение промежуточного представления]]
  - [[#операторы][Операторы]]
  - [[#примеры-работы-pigletql][Примеры работы PigletQL]]
- [[#выводы][Выводы]]

* TODO Структура интерпретатора SQL

  TODO: picture

  Большая часть современных популярных баз данных предоставляет интерфейс к данным в виде
  декларативного языка запросов SQL. Современный SQL очень сложен, его международный стандарт
  изложен на тысячах страниц не самого простого текста.

  Первые интерпретаторы запросов SQL исполняли запросы непосредственно из дерева разбора, но вскоре
  разработчики переключились на использование специальных промежуточных представлений.

  Ключевым кандидатом на роль промежуточного представления стала реляционная алгебра. Реляционная
  алгебра - язык, где явно описываются преобразования (/операторы/), проводимые над данными: выбор
  подмножества данных по какому-то предикату, соединение данных из разных источников и так далее.
  Кроме того, это алгебра в математическом смысле, то есть для нее формализовано большое количество
  упрощающих преобразований. Над запросом в форме дерева операторов реляционной алгебры удобно
  проводить оптимизирующие преобразования.

  Существуют важные отличия между внутренним представлением в базах данных и оригинальной
  реляционной алгеброй, поэтому правильней ее называеть /логической алгеброй/.

  Проверка валидности запроса обычно проводится при компиляции дерева разбора в операторы логической
  алгебры и соответствует стадии семантического анализа. Роль таблицы символов в базах данных играет
  роль /каталог базы данных/, где хранится информация о /схеме/ и метаданных базы данных: таблицах,
  колонках таблиц, правах пользователей и т.д..

  По сравнению с интерпретаторами языков общего назначения у интерпретаторов баз данных есть еще
  одна особенность: сильные различия в структуре данных, к которым предполагается делать запросы.
  Таблицы (/отношения/ в терминах реляционной алгебры и документации некоторых БД) с данными бывают
  разных размеров, на некоторых колонках (/атрибутах/ отношений) могут быть индексы и т.д. То есть в
  зависимости от /схемы/ и данных в БД запрос надо исполнять разными алгоритмами и разном порядке.

  Для решения этой задачи было введено еще одно древовидное внутреннее представление - /физическая
  алгебра/. В зависимости от наличия индексов на колонках, объема данных в отдельных таблицах и
  структуры дерева логической алгебры предлагаются разные формы дерева физической алгебры, из
  которых выбирается оптимальный - который и показывают БД в качестве плана запроса. В обычных
  компиляторах этому этапу соответствует этап выбора инструкций.

  Последним этапом работы интерпретатора является непосредственно исполнение дерева операторов
  физической алгебры.

* TODO Модель Volcano и исполнение запросов

  TODO: picture

  Интерпретаторы дерева физической алгебры в закрытых коммерческих БД использовались практически
  всегда, но ключевая публикация на эту тему связана с экспериментальным оптимизатором Volcano,
  разрабатывавшемся в начале 90-х.

  В модели Volcano операторы дерева физической алгебры каждый превращается в структуру с тремя
  функциями: open, next, close. Кроме функций оператор содержит рабочее состояние - state. Функция
  open инициирует состояние оператора, next возвращает либо следующий /кортеж/ (англ. tuple), либо
  NULL если кортежей большей не осталось. Функция close деаллоцирует рабочее состояние.

  Каждый оператор, таким образом, перебирает кортежи какого-либо постоянно существующего отношения,
  либо отношения, формируемого перебором кортежей дочерних операторов.

  Операторы могут быть вложены друг в друга, чтобы сформировать дерево операторов физической
  алгебры. В терминах современных языков высокого уровня дерево таких операторов представляет собой
  каскад итераторов.

  От модели Volcano отталкиваются даже промышленные интерпретаторы запросов в реляционных СУБД,
  поэтому именно эту модель я взял в качестве основы интерпретатора PigletQL.

* TODO PigletQL

  PigletQL поддерживает создание таблиц в стиле SQL, но ограничивается единственным типом -
  32-битными положительными целыми числами. Все таблицы располагаются в памяти. Система работает в
  один поток и не предлагает механизма транзакций. В PigletQL нет оптимизатора, и запросы SELECT
  компилируются прямо в дерево операторов.

  TODO: PigletQL structure picture

  К таблицам можно выполнять запросы, соответствующие простейшим операторам физической алгебры: scan,
  project, select, join, sort.

  Пример сессии пользователя в PigletQL:

  #+BEGIN_EXAMPLE
  > ./pigletql
  > CREATE TABLE tab1 (col1,col2,col3);
  > INSERT INTO tab1 VALUES (1,2,3);
  > INSERT INTO tab1 VALUES (4,5,6);
  > SELECT col1,col2,col3 FROM tab1;
  col1 col2 col3
  1 2 3
  4 5 6
  rows: 2
  > SELECT col1 FROM tab1 ORDER BY col1 DESC;
  col1
  4
  1
  rows: 2
  #+END_EXAMPLE

** TODO Лексический и синтаксический анализаторы

   PigletQL - очень простой язык. Чтобы не вносить зависимостей в код я решил не использовать
   никаких сторонних инструментов на этапах лексического и синтаксического анализа.

   Вручную написанный лексический анализатор получает строку запроса на вход и отдает один за другим
   лексемы (токены). Вот сами токены:

   #+BEGIN_SRC c

   typedef enum token_type {
       TOKEN_IDENT,
       TOKEN_NUMBER,
       TOKEN_STAR,
       TOKEN_COMMA,
       TOKEN_SEMICOLON,
       TOKEN_LPAREN,
       TOKEN_RPAREN,
       TOKEN_EQUAL,
       TOKEN_LESS,
       TOKEN_GREATER,
       TOKEN_SELECT,
       TOKEN_CREATE,
       TOKEN_TABLE,
       TOKEN_INSERT,
       TOKEN_FROM,
       TOKEN_WHERE,
       TOKEN_AND,
       TOKEN_ORDER,
       TOKEN_BY,
       TOKEN_ASC,
       TOKEN_DESC,
       TOKEN_INTO,
       TOKEN_VALUES,
       TOKEN_ERROR,                /* failed to scan */
       TOKEN_EOS                   /* end of stream */
   } token_type;

   typedef struct token_t {
       token_type type;            /* token type tag */
       const char *start;          /* start of the token string */
       int length;                 /* length of the token string */
   } token_t;

   #+END_SRC

   Интерфейс анализатора:

   #+BEGIN_SRC c

   typedef struct scanner_t scanner_t;

   scanner_t *scanner_create(const char *string);

   void scanner_destroy(scanner_t *scanner);

   token_t scanner_next(scanner_t *scanner);

   #+END_SRC

   Синтаксический анализ проводится методом рекурсивного спуска. Результат разбора - один из трех
   поддерживаемых видов запроса:

   #+BEGIN_SRC c

     typedef enum query_tag {
         QUERY_SELECT,
         QUERY_CREATE_TABLE,
         QUERY_INSERT,
     } query_tag;

     /*
      * ... query_select_t, query_create_table_t, query_insert_t definitions ...
      **/

     typedef struct query_t {
         query_tag tag;
         union {
             query_select_t select;
             query_create_table_t create_table;
             query_insert_t insert;
         } as;
     } query_t;

   #+END_SRC

   Интерфейс синтаксического анализатора:

   #+BEGIN_SRC c

   query_t *query_create(void);

   void query_destroy(query_t *query);

   parser_t *parser_create(void);

   void parser_destroy(parser_t *parser);

   bool parser_parse(parser_t *parser, scanner_t *scanner, query_t *query);

   #+END_SRC

   Самый сложный вид запросов в PigletQL - SELECT. Ему соответствует структура данных
   query_select_t:

   #+BEGIN_SRC c

   typedef struct query_select_t {
       /* Attributes to output */
       attr_name_t attr_names[MAX_ATTR_NUM];
       uint16_t attr_num;

       /* Relations to get tuples from */
       rel_name_t rel_names[MAX_REL_NUM];
       uint16_t rel_num;

       /* Predicates to apply to tuples */
       query_predicate_t predicates[MAX_PRED_NUM];
       uint16_t pred_num;

       /* Pick an attribute to sort by */
       bool has_order;
       attr_name_t order_by_attr;
       sort_order_t order_type;
   } query_select_t;

   #+END_SRC

   Структура содержит описание запроса: массив запрошенных пользователем атрибутов; список
   источников данных - отношений; массив предикатов, фильтрующих кортежи; и информация об атрибуте,
   используемом для сортировки результатов.

** TODO Семантический анализатор

   Фаза семантического анализа в обычном SQL включает проверку существования перечисленных таблиц,
   колонок в таблицах и корректности типов в выражениях запроса. Для проверок, связанных с таблицами
   и колонками, используется /каталог/ базы данных, где хранится вся информация о структуре данных БД.

   В PigletQL сложных выражений не бывает, поэтому проверка запроса сводится к проверке метаданных
   таблиц и колонок по каталогу:

   #+BEGIN_SRC c

   static bool validate_select(catalogue_t *cat, const query_select_t *query)
   {
       /* All the relations should exist */
       for (size_t rel_i = 0; rel_i < query->rel_num; rel_i++) {
           if (catalogue_get_relation(cat, query->rel_names[rel_i]))
               continue;

           fprintf(stderr, "Error: relation '%s' does not exist\n", query->rel_names[rel_i]);
           return false;
       }

       /* Relation names should be unique */
       if (!rel_names_unique(query->rel_names,query->rel_num))
           return false;

       /* Attribute names should be unique */
       if (!attr_names_unique(query->attr_names, query->attr_num))
           return false;

       /* Attributes should be present in relations listed */
       for (size_t attr_i = 0; attr_i < query->attr_num; attr_i++) {
           bool attr_found = false;
           for (size_t rel_i = 0; rel_i < query->rel_num; rel_i++) {
               relation_t *rel = catalogue_get_relation(cat, query->rel_names[rel_i]);
               if (!relation_has_attr(rel, query->attr_names[attr_i]))
                   continue;
               attr_found = true;
               break;
           }
           if (attr_found)
               continue;

           const char *msg = "Error: unknown attribute name '%s'\n";
           fprintf(stderr, msg, query->attr_names[attr_i]);
           return false;
       }

       /* Order by attribute should be available in the list of attributes chosen */
       if (query->has_order) {
           if (!attr_in_attr_names(query->order_by_attr, query->attr_names, query->attr_num)) {
               const char *msg = "Error: unknown order by attribute '%s'\n";
               fprintf(stderr, msg, query->order_by_attr);
               return false;
           }
       }

       /* Predicate attributes should be available in the list of attributes projected */
       for (size_t pred_i = 0; pred_i < query->pred_num; pred_i++) {
           const query_predicate_t *predicate = &query->predicates[pred_i];

           /* Attribute on the left should always be there */
           {
               token_t token = predicate->left;
               char attr_name_buf[512] = {0};
               strncpy(attr_name_buf, token.start, (size_t)token.length);

               if (!attr_in_attr_names(attr_name_buf, query->attr_names, query->attr_num)) {
                   const char *msg = "Error: unknown left-hand side attribute name '%s' in predicate %zu\n";
                   fprintf(stderr, msg, attr_name_buf, pred_i);
                   return false;
               }
           }

           /* Attribute on the right? */
           {
               token_t token = predicate->right;
               if (token.type == TOKEN_IDENT) {
                   char attr_name_buf[512] = {0};
                   strncpy(attr_name_buf, token.start, (size_t)token.length);

                   if (!attr_in_attr_names(attr_name_buf, query->attr_names, query->attr_num)) {
                       const char *msg = "Error: unknown right-hand side attribute name '%s' in predicate %zu\n";
                       fprintf(stderr, msg, attr_name_buf, pred_i);
                       return false;
                   }
               }
           }
       }

       return true;
   }

   #+END_SRC

   Если запрос валиден, то следующим этапом становится компиляция дерево операторов, которое и будет
   выполняться непосредственно.

** TODO Компиляция запросов в промежуточное представление

   В полноценном интерпретаторе SQL внутренних представлений бывает несколько. Обычно это
   представление, удобное для оптимизатора, и еще одно, более подходящее для исполнения:
   соответственно деревья операторов логическая и физической алгебр.

   PigletQL непосредственно исполняет только простые запросы CREATE TABLE или INSERT, которым
   соответствуют структуры query_create_table_t и query_insert_t. Запросы же SELECT компилируются во
   внутреннее представление, которое и будет исполняться интерпретатором.

   Дерево операторов строится относительно снизу вверх, в определенной последовательности:

   1. Из правой части запроса ("... FROM relation1, relation2, ...") получаются имена искомых
      отношений, для каждого из которых создается оператор scan.

   2. Сканирующие операторы объединяются в левое двоичное дерево через оператор join.

   3. Атрибуты, запрошенные пользователем ("SELECT attr1, attr2 ..."), выбираются еще один оператор
      project.

   4. Если указаны какие-либо предикаты ("... WHERE a=1 AND b>10 ..."), то к дереву сверху
      добавляется оператор select.

   5. Если указан способ сортировки результата ("... ORDER BY attr1 DESC"), то к вершине дерева
      добавляется оператор sort.

   Компиляция в коде PigletQL:

   #+BEGIN_SRC c

   operator_t *compile_select(catalogue_t *cat, const query_select_t *query)
   {
       /* Current root operator */
       operator_t *root_op = NULL;

       /* 1. Scan ops */
       /* 2. Join ops*/

       {
           size_t rel_i = 0;
           relation_t *rel = catalogue_get_relation(cat, query->rel_names[rel_i]);
           root_op = scan_op_create(rel);
           rel_i += 1;

           for (; rel_i < query->rel_num; rel_i++) {
               rel = catalogue_get_relation(cat, query->rel_names[rel_i]);
               operator_t *scan_op = scan_op_create(rel);
               root_op = join_op_create(root_op, scan_op);
           }
       }

       /* 3. Project */
       root_op = proj_op_create(root_op, query->attr_names, query->attr_num);

       /* 4. Select */
       if (query->pred_num > 0) {
           operator_t *select_op = select_op_create(root_op);
           for (size_t pred_i = 0; pred_i < query->pred_num; pred_i++) {
               query_predicate_t predicate = query->predicates[pred_i];

               /* On the left we always get an identifier */
               assert(predicate.left.type == TOKEN_IDENT);

               attr_name_t left_attr_name = {0};
               strncpy(left_attr_name, predicate.left.start, (size_t)predicate.left.length);

               select_predicate_op pred_op = 0;
               switch (predicate.op.type) {
               case TOKEN_GREATER:
                   pred_op = SELECT_GT;
                   break;
               case TOKEN_LESS:
                   pred_op = SELECT_LT;
                   break;
               case TOKEN_EQUAL:
                   pred_op = SELECT_EQ;
                   break;
               default:
                   /* Uknown predicate type */
                   assert(false);
               }

               /* On the right it's either a constant or another identifier */
               if (predicate.right.type == TOKEN_IDENT) {
                   attr_name_t right_attr_name = {0};
                   strncpy(right_attr_name, predicate.right.start, (size_t)predicate.right.length);

                   select_op_add_attr_attr_predicate(select_op, left_attr_name, pred_op, right_attr_name);
               } else if (predicate.right.type == TOKEN_NUMBER) {
                   char buf[128] = {0};
                   strncpy(buf, predicate.right.start, (size_t)predicate.right.length);

                   value_type_t right_const = 0;
                   sscanf(buf, "%" SCN_VALUE, &right_const);

                   select_op_add_attr_const_predicate(select_op, left_attr_name, pred_op, right_const);
               } else {
                   /* Invalid token */
                   assert(false);
               }
           }
           root_op = select_op;
       }

       /* 5. Sort */
       if (query->has_order)
           root_op = sort_op_create(root_op, query->order_by_attr, query->order_type);

       return root_op;
   }

   #+END_SRC

   TODO: пара примеров деревьев, побольше и поменьше

** TODO Исполнение промежуточного представления

   В большим интерпретаторе над деревом операторов обычно проводятся многочисленные оптимизирующие
   преобразования. PigletQL - простой интерпретатор, где дерево исполняется сразу после
   формирования.

   Модель исполнения Volcano подразумевает интерфейс работы с операторами через три общие для всех
   операторов операции open/next/close. В сущности, это просто итераторы. Каждый из итераторов может
   сам вызвать те же функции вложенных итераторов.

   Исполнение запросов SELECT в PigletQL:

   #+BEGIN_SRC c

   bool eval_select(catalogue_t *cat, const query_select_t *query)
   {
       /* Compile the operator tree:  */
       operator_t *root_op = compile_select(cat, query);


       /* Eval the tree: */
       {
           root_op->open(root_op->state);

           size_t tuples_received = 0;
           tuple_t *tuple = NULL;
           while((tuple = root_op->next(root_op->state))) {
               /* attribute list for the first row only */
               if (tuples_received == 0)
                   dump_tuple_header(tuple);

               /* A table of tuples */
               dump_tuple(tuple);

               tuples_received++;
           }
           printf("rows: %zu\n", tuples_received);

           root_op->close(root_op->state);
       }

       root_op->destroy(root_op);

       return true;
   }

   #+END_SRC

   Здесь запрос сначала компилируется функцией compile_select, возвращающей корень дерева
   операторов; после чего у корневого оператора вызываются те самые open/next/close. Каждый вызов
   next либо возвращает следующий кортеж, либо NULL. В последнем случае все кортежи были извлечены,
   и следует вызвать закрывающую итератор функцию close.

   Полученные кортежи просто пересчитываются и выводятся в stderr.

** TODO Операторы

   Самое интересное в PigletQL - дерево операторов, и хочется показать устройство хотя бы одного из
   них.

   Интерфейс у всех операторов общий и состоит из указателей на функции open/next/close и
   дополнительной служебная функция (destroy), высвобождающей ресурсы всего дерева операторов разом:

   #+BEGIN_SRC c

   typedef struct operator_t operator_t;

   typedef void (*op_open)(void *state);
   typedef tuple_t *(*op_next)(void *state);
   typedef void (*op_close)(void *state);
   typedef void (*op_destroy)(operator_t *op);

   /* The operator itself is just 4 pointers to related ops and operator state */
   struct operator_t {
       op_open open;
       op_next next;
       op_close close;
       op_destroy destroy;

       void *state;
   } ;

   #+END_SRC

   Помимо функций в операторе может содержаться произвольное внутреннее состояние (указатель state).

   Оператор, с которого начинается выполнение любого запроса - scan. Он просто перебирает все
   кортежи отношения. Внутреннее состояние у scan это указатель на отношение, откуда будут
   извлекаться кортежи, индекс следующего кортежа в отношении и структура-ссылка на текущий кортеж,
   переданный пользователю:

   #+BEGIN_SRC c

   typedef struct scan_op_state_t {
       /* A reference to the relation being scanned */
       const relation_t *relation;
       /* Next tuple index to retrieve from the relation */
       uint32_t next_tuple_i;
       /* A structure to be filled with references to tuple data */
       tuple_t current_tuple;
   } scan_op_state_t;

   #+END_SRC

   Для создания состояния оператора scan необходимо отношение-источник, все остальное (указатели на
   соответствующие функции) уже известно:

   #+BEGIN_SRC c

   operator_t *scan_op_create(const relation_t *relation)
   {
       operator_t *op = calloc(1, sizeof(*op));
       assert(op);

       *op = (operator_t) {
           .open = scan_op_open,
           .next = scan_op_next,
           .close = scan_op_close,
           .destroy = scan_op_destroy,
       };

       scan_op_state_t *state = calloc(1, sizeof(*state));
       assert(state);

       *state = (scan_op_state_t) {
           .relation = relation,
           .next_tuple_i = 0,
           .current_tuple.tag = TUPLE_SOURCE,
           .current_tuple.as.source.tuple_i = 0,
           .current_tuple.as.source.relation = relation,
       };
       op->state = state;


       return op;
   }

   #+END_SRC

   Операции open/close в случае scan просто сбрасывают ссылки обратно на первый элемент отношения:

   #+BEGIN_SRC c

   void scan_op_open(void *state)
   {
       scan_op_state_t *op_state = (typeof(op_state)) state;
       op_state->next_tuple_i = 0;
       tuple_t *current_tuple = &op_state->current_tuple;
       current_tuple->as.source.tuple_i = 0;
   }

   void scan_op_close(void *state)
   {
       scan_op_state_t *op_state = (typeof(op_state)) state;
       op_state->next_tuple_i = 0;
       tuple_t *current_tuple = &op_state->current_tuple;
       current_tuple->as.source.tuple_i = 0;
   }

   #+END_SRC

   Вызов next либо возвращает следующий кортеж, либо, если кортежей в отношении больше нет, NULL:

   #+BEGIN_SRC c

   tuple_t *scan_op_next(void *state)
   {
       scan_op_state_t *op_state = (typeof(op_state)) state;
       if (op_state->next_tuple_i >= op_state->relation->tuple_num)
           return NULL;

       tuple_source_t *source_tuple = &op_state->current_tuple.as.source;
       source_tuple->tuple_i = op_state->next_tuple_i;
       op_state->next_tuple_i++;

       return &op_state->current_tuple;
   }

   #+END_SRC

** TODO Примеры работы PigletQL

   TODO: get an op tree for every operator (or maybe make a way to dump the tree?)

* TODO Выводы
